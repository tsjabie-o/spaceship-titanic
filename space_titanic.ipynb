{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "dat_train = pd.read_csv(\"data/train.csv\")\n",
    "dat_test = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "# Quick first look at the data\n",
    "dat_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "As we can see from the code below, there's quite some rows with missing values. Therefore we cannot just drop all our missing values as that would leave us with 75% of the datapoints. We'll have to fill in missing values where we can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# function for reuse\n",
    "def calc_missing():\n",
    "    missing = dat_train.isnull().sum()\n",
    "    print(\"Percent values missing: \", missing.sum()/ np.product(dat_train.shape))\n",
    "    print(\"Percent rows with missing values: \", dat_train.isnull().any(axis=1).sum() / len(dat_train))\n",
    "    print(\"Overview of missing values:\\n\\n\", missing)\n",
    "\n",
    "calc_missing()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PassengerId\n",
    "I will be creating two seperate features `Group` and `PinG` (person in group) which I'll extract from the `PassengerId` feature. First of all because it will help us fill missing values in a more informed manner, and also because I'll want to create a new feature from this information later on. We can then also get rid of the `PassengerId` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def dt_group(id: str):\n",
    "    group = int(id.split(\"_\")[0])\n",
    "    person = int(id.split(\"_\")[1])\n",
    "    return((group, person))\n",
    "\n",
    "dat_train[\"Group\"] = dat_train.apply(\n",
    "    lambda row: dt_group(row[\"PassengerId\"])[0],\n",
    "    axis=1\n",
    ")\n",
    "dat_train[\"PinG\"] = dat_train.apply(\n",
    "    lambda row: dt_group(row[\"PassengerId\"])[1],\n",
    "    axis=1\n",
    ")\n",
    "dat_train.drop(\"PassengerId\", axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name\n",
    "I will also be removing the `Name` column, since I will not be using it in my models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "dat_train = dat_train.drop(\"Name\", axis=1)\n",
    "dat_test = dat_test.drop(\"Name\", axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age\n",
    "For the `Age` values, we can see that the ages resemble a normal distribution with a mean around the 20-30 years. Therefore I think it's okay to fill the missing age values with the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "plt.hist(dat_train[\"Age\"], bins=range(0,80, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "dat_train[\"Age\"].fillna(dat_train[\"Age\"].mean(), inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoomService, FoodCourt, ShoppingMall, Spa and VRDeck\n",
    "\n",
    "For the `RoomService`, `FoodCourt`, `ShoppingMall`, `Spa` and `VRDeck` values, I will try two different solutions:\n",
    "- fill mising values with 0. I will do this because as we can see below, 0 is by far the most common value in these columns. \n",
    "- fill the missing value with the mean of each of the other (known) values in the luxury amenities\n",
    "We'll see later whether the more advanced method has an advantage. Just from looking at some random examples there is quite some difference in the values it eventually fills in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Checking amount of 0's in these categories\n",
    "for column in [\"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]:\n",
    "    print(f\"N. of values == 0 in \\\"{column}\\\" column: \", len(dat_train[dat_train[column] == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "simple = False\n",
    "\n",
    "if simple:\n",
    "    # Filling NaN's with zeroes\n",
    "    for column in [\"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]:\n",
    "        dat_train[column].fillna(0, inplace=True)\n",
    "\n",
    "else:\n",
    "    # Fill with mean of known amounts in other luxury spending columns\n",
    "    columns = [\"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]\n",
    "    for column in columns:\n",
    "        dat_train[column] = dat_train.apply(\n",
    "            lambda row: row[columns].mean() if np.isnan(row[column]) else row[column],\n",
    "            axis=1\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HomePlanet, Destination, Cabin, VIP and CryoSleep\n",
    "For the `HomePlanet`, `Destination`, `Cabin`, `VIP` and `CryoSleep` features, I will be using the mode of that feature for the group the passenger is in, since I'm assuming and seeing in the data that they'll mostly have the same home planet, destination, cabin and VIP status as their group. For the `CryoSleep`, the data seems to suggest this varies within groups as well, but using the group mode is probably still a safer bet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# small function for getting mode of feature in a group\n",
    "def find_mode_feature(group: int, feature: str):\n",
    "    g = dat_train[dat_train[\"Group\"] == group]\n",
    "    m = g[feature].mode()\n",
    "\n",
    "    # if each person in the group has NaN (which happens for one-person groups), we use the mode of the entire dataset\n",
    "    if len(m) == 0:\n",
    "        return dat_train[feature].mode()[0]\n",
    "    else:\n",
    "        return(g[feature].mode()[0])\n",
    "\n",
    "features = [\"HomePlanet\", \"Destination\", \"Cabin\", \"VIP\", \"CryoSleep\"]\n",
    "\n",
    "for feature in features:\n",
    "    dat_train[feature] = dat_train.apply(\n",
    "        lambda row: find_mode_feature(row[\"Group\"], feature) if (str(row[feature]) == \"nan\") else row[feature],\n",
    "        axis=1\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That leaves us with no missing values in the training set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "calc_missing()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection and engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Cabin', 0.8888631537383956), ('CryoSleep', 0.45800083221339233), ('RoomService', 0.24112357990296215), ('Spa', 0.21854462654893309), ('VRDeck', 0.2048736906578474), ('HomePlanet', 0.19510494531678743), ('Destination', 0.11079133761875486), ('Age', 0.07424911053933278), ('FoodCourt', 0.04558341664358489), ('VIP', 0.037260832266615314), ('ShoppingMall', 0.009391027784015404)]\n"
     ]
    }
   ],
   "source": [
    "# defining a function for calculating Cramer's V statistic\n",
    "def cramers_V(feature: str):\n",
    "    ct = pd.crosstab(dat_train[feature], dat_train[\"Transported\"], margins=False, dropna=True)\n",
    "    x2 = stats.chi2_contingency(ct, correction=False)[0]\n",
    "    n = ct.sum().sum()\n",
    "    cv = np.sqrt((x2/n) / (min(ct.shape) - 1))\n",
    "    return(cv)\n",
    "\n",
    "# dict of features and their correlation\n",
    "feat_cor = dict()\n",
    "\n",
    "for feature in [\"HomePlanet\", \"CryoSleep\", \"Cabin\", \"Destination\", \"VIP\"]:\n",
    "    feat_cor[feature] = cramers_V(feature)\n",
    "\n",
    "for feature in [\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]:\n",
    "    c = dat_train[[feature, \"Transported\"]].corr()\n",
    "    feat_cor[feature] = abs(c.iloc[0,1])\n",
    "\n",
    "print(sorted(feat_cor.items(), key=lambda x:x[1], reverse=True))\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
